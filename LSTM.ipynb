{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import sys\n",
    "import matplotlib.dates as mdates\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def showGraph(data):\n",
    "    plt.figure()\n",
    "    plt.plot(data)\n",
    "    plt.show()\n",
    "def saveGraph(data, file_name):\n",
    "    plt.figure(dpi=360)\n",
    "    plt.plot(data)\n",
    "    plt.savefig('results/' + file_name)\n",
    "# convert dataset to x and y\n",
    "# def create_dataset(dataset, look_back=1):\n",
    "#     dataX, dataY = [], []\n",
    "#     for i in range(len(dataset) - look_back - 1):\n",
    "#         a = dataset[i:(i+look_back), 0]\n",
    "#         dataX.append(a)\n",
    "#         dataY.append(dataset[i + look_back, 0])\n",
    "#     return numpy.array(dataX), numpy.array(dataY)\n",
    "def relative_error(xs, ys):\n",
    "    error = 0\n",
    "    zero = 0\n",
    "    for i in range(len(xs)):\n",
    "        if ys[i] != 0:\n",
    "            error += abs(xs[i]-ys[i])*100 / ys[i]\n",
    "        else:\n",
    "            zero += 1\n",
    "    error /= (len(xs) - zero)\n",
    "    return error\n",
    "def read_data(file_name):\n",
    "    return pandas.read_csv('datas/' + file_name, usecols=[1], sep='|')\n",
    "def saveGraphWithDate(dates, y_axis, file_name, format_date):\n",
    "    plt.figure(dpi=360)\n",
    "    x = [dt.datetime.strptime(d,format_date).date() for d in dates]\n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m/%Y'))\n",
    "    plt.gca().xaxis.set_major_locator(mdates.MonthLocator(interval=6))\n",
    "    plt.plot(x,y_axis)\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    plt.savefig('results/' + file_name)\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    trainX, trainY, testX, testY = [], [], [], []\n",
    "    for i in range(len(dataset) - look_back):\n",
    "        x = dataset[i:(i+look_back), :]\n",
    "        if i <= int(len(dataset) * 0.67):\n",
    "            trainX.append(x)\n",
    "            trainY.append(dataset[i+look_back])\n",
    "        else:\n",
    "            testX.append(x)\n",
    "            testY.append(dataset[i+look_back])\n",
    "    return numpy.array(trainX), numpy.array(trainY), numpy.array(testX), numpy.array(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = 'data_stock_market.csv'\n",
    "result_path = 'raw'\n",
    "format_date='%d/%m/%Y'\n",
    "epochs = 10\n",
    "look_back = 1\n",
    "\n",
    "print('2. LSTM ')\n",
    "# dataset = read_data(datafile)\n",
    "# saveGraph(dataset, result_path + '/data')\n",
    "dataframe = pandas.read_csv('datas/' + datafile, sep='|')\n",
    "saveGraphWithDate(dataframe['date'], dataframe['close_price'], result_path + '/data', format_date)\n",
    "dataset = dataframe['close_price'].values.reshape(dataframe['close_price'].shape[0], 1)\n",
    "\n",
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "# dataset.loc[-1] = [max(dataset.values)*2]\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "# dataset = dataset[:-1]\n",
    "\n",
    "# split into train and test sets\n",
    "train_size = int(len(dataset) * 0.67)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "# reshape into X=t and Y=t+1\n",
    "\n",
    "trainX, trainY, testX, testY = create_dataset(dataset, look_back)\n",
    "trainX = trainX.reshape(trainX.shape[0], look_back, 1)\n",
    "testX = testX.reshape(testX.shape[0], look_back, 1)\n",
    "trainY = trainY.reshape(trainY.shape[0], 1)\n",
    "testY = testY.reshape(testY.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input = Input(shape=(look_back, 1))\n",
    "model_output = LSTM(1, return_sequences=False)(model_input)\n",
    "model = Model(input=model_input, output=model_output)\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=epochs, batch_size=1, verbose=2)\n",
    "\n",
    "# loop predict only the next day and fit to model\n",
    "print('----- Predict Trend -----')\n",
    "predict = []\n",
    "dates_test = dataframe['date'].values[(len(dataset) - len(testY) - 1):(len(dataset)-1)]\n",
    "\n",
    "for index, today_close_price in enumerate(testX):\n",
    "    predict_tomorrow = model.predict(numpy.array([today_close_price]))[0]\n",
    "    predict.append(predict_tomorrow)\n",
    "    model.fit(numpy.array([today_close_price]), numpy.array([testY[index]]), epochs=epochs, batch_size=1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict = scaler.inverse_transform(predict)\n",
    "# testX = scaler.inverse_transform(testX[:, 0])\n",
    "testY = scaler.inverse_transform(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/' + result_path + '/result.csv', 'w+') as file:\n",
    "    file.write('close_price|predict\\n')\n",
    "    for i in range(len(predict)):\n",
    "        file.write(str(testY[i][0]) + '|' + str(predict[i][0]) + '\\n')\n",
    "plt.figure(dpi=200)\n",
    "plt.plot(testY, linewidth=0.5)\n",
    "plt.plot(predict, linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = scaler.inverse_transform(testX[:, look_back - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_trend_reallity = [int(numpy.sign(b[0] - a[0])) for a, b in zip(today, testY)]\n",
    "_trend_predict = [int(numpy.sign(b[0] - a[0])) for a, b in zip(today, predict)]\n",
    "_correct = [1 if a == b else 0 for a, b in zip(_trend_reallity, _trend_predict)]\n",
    "print('Percent correct: %.2f' % (100*sum(_correct)/len(_correct)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 5):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(range(1, 10)) + list(range(12, 40, 2)) + list(range(45, 100, 5)) + list(range(120, 240, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "d:\\python35\\lib\\site-packages\\ipykernel_launcher.py:85: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ls...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2s - loss: 0.0814\n",
      "----- Predict Trend -----\n",
      "Epoch 1/1\n",
      "3s - loss: 0.0737\n",
      "----- Predict Trend -----\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import sys\n",
    "import matplotlib.dates as mdates\n",
    "import datetime as dt\n",
    "\n",
    "def saveGraph(data, file_name):\n",
    "    plt.figure(dpi=360)\n",
    "    plt.plot(data)\n",
    "    plt.savefig('results/' + file_name)\n",
    "def relative_error(xs, ys):\n",
    "    error = 0\n",
    "    zero = 0\n",
    "    for i in range(len(xs)):\n",
    "        if ys[i] != 0:\n",
    "            error += abs(xs[i]-ys[i])*100 / ys[i]\n",
    "        else:\n",
    "            zero += 1\n",
    "    error /= (len(xs) - zero)\n",
    "    return error\n",
    "def read_data(file_name):\n",
    "    return pandas.read_csv('datas/' + file_name, usecols=[1], sep='|')\n",
    "def saveGraphWithDate(dates, y_axis, file_name, format_date):\n",
    "    plt.figure(dpi=360)\n",
    "    x = [dt.datetime.strptime(d,format_date).date() for d in dates]\n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m/%Y'))\n",
    "    plt.gca().xaxis.set_major_locator(mdates.MonthLocator(interval=6))\n",
    "    plt.plot(x,y_axis)\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    plt.savefig('results/' + file_name)\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    trainX, trainY, testX, testY = [], [], [], []\n",
    "    for i in range(len(dataset) - look_back):\n",
    "        x = dataset[i:(i+look_back), :]\n",
    "        if i <= int(len(dataset) * 0.67):\n",
    "            trainX.append(x)\n",
    "            trainY.append(dataset[i+look_back])\n",
    "        else:\n",
    "            testX.append(x)\n",
    "            testY.append(dataset[i+look_back])\n",
    "    return numpy.array(trainX), numpy.array(trainY), numpy.array(testX), numpy.array(testY)\n",
    "\n",
    "\n",
    "\n",
    "datafile = 'data_stock_market.csv'\n",
    "result_path = 'raw'\n",
    "format_date='%d/%m/%Y'\n",
    "epochs = 1\n",
    "\n",
    "percents_correct = []\n",
    "look_backs = list(range(1, 3))\n",
    "\n",
    "for look_back in look_backs:\n",
    "    dataframe = pandas.read_csv('datas/' + datafile, sep='|')\n",
    "    dataset = dataframe['close_price'].values.reshape(dataframe['close_price'].shape[0], 1)\n",
    "\n",
    "    # normalize the dataset\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    dataset = scaler.fit_transform(dataset)\n",
    "\n",
    "    # split into train and test sets\n",
    "    train_size = int(len(dataset) * 0.67)\n",
    "    test_size = len(dataset) - train_size\n",
    "    train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "\n",
    "    trainX, trainY, testX, testY = create_dataset(dataset, look_back)\n",
    "    trainX = trainX.reshape(trainX.shape[0], look_back, 1)\n",
    "    testX = testX.reshape(testX.shape[0], look_back, 1)\n",
    "    trainY = trainY.reshape(trainY.shape[0], 1)\n",
    "    testY = testY.reshape(testY.shape[0], 1)\n",
    "\n",
    "    model_input = Input(shape=(look_back, 1))\n",
    "    model_output = LSTM(1, return_sequences=False)(model_input)\n",
    "    model = Model(input=model_input, output=model_output)\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(trainX, trainY, epochs=epochs, batch_size=1, verbose=2)\n",
    "\n",
    "\n",
    "    print('----- Predict Trend -----')\n",
    "    predict = []\n",
    "    dates_test = dataframe['date'].values[(len(dataset) - len(testY) - 1):(len(dataset)-1)]\n",
    "\n",
    "    for index, today_close_price in enumerate(testX):\n",
    "        predict_tomorrow = model.predict(numpy.array([today_close_price]))[0]\n",
    "        predict.append(predict_tomorrow)\n",
    "        model.fit(numpy.array([today_close_price]), numpy.array([testY[index]]), epochs=epochs, batch_size=1, verbose=0)\n",
    "\n",
    "    predict = scaler.inverse_transform(predict)\n",
    "    testY = scaler.inverse_transform(testY)\n",
    "\n",
    "    with open('results/' + result_path + '/result.csv', 'w+') as file:\n",
    "        file.write('close_price|predict\\n')\n",
    "        for i in range(len(predict)):\n",
    "            file.write(str(testY[i][0]) + '|' + str(predict[i][0]) + '\\n')\n",
    "\n",
    "    today = scaler.inverse_transform(testX[:, look_back - 1])\n",
    "\n",
    "    _trend_reallity = [int(numpy.sign(b[0] - a[0])) for a, b in zip(today, testY)]\n",
    "    _trend_predict = [int(numpy.sign(b[0] - a[0])) for a, b in zip(today, predict)]\n",
    "    _correct = [1 if a == b else 0 for a, b in zip(_trend_reallity, _trend_predict)]\n",
    "    _percent_correct = 100*sum(_correct)/len(_correct)\n",
    "    percents_correct.append({'look_back': look_back, 'percent': _percent_correct})\n",
    "\n",
    "with open('results/' + result_path + '/percents.csv', 'w+') as file:\n",
    "    file.write('look_back|percent\\n')\n",
    "    for i in percents_correct:\n",
    "        file.write(str(i['look_back']) + '|' + str(i['percent']) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
