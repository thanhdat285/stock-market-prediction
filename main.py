
# coding: utf-8

# In[1]:


import numpy
import matplotlib.pyplot as plt
import pandas
import math
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error


# In[15]:


def showGraph(data):
    plt.plot(data)
    plt.show()
# convert dataset to x and y
def create_dataset(dataset, look_back=1):
    dataX, dataY = [], []
    for i in range(len(dataset) - look_back - 1):
        a = dataset[i:(i+look_back), 0]
        dataX.append(a)
        dataY.append(dataset[i + look_back, 0])
    return numpy.array(dataX), numpy.array(dataY)


# In[40]:

loop = 20

for i in range(loop):
  dataset = pandas.read_csv('data_stock_market.csv', usecols=[1])
  data_standard = dataset


  # In[7]:


  # showGraph(dataset)


  # In[10]:


  # normalize the dataset
  scaler = MinMaxScaler(feature_range=(0, 1))
  dataset = scaler.fit_transform(dataset)
  # showGraph(dataset)


  # In[13]:


  # split into train set and test set
  train_size = int(len(dataset) * 0.67)
  # train_size = int(len(dataset))
  test_size = len(dataset) - train_size
  train, test = dataset[0:train_size, :], dataset[train_size:len(dataset), :]
  # train = dataset[0:train_size, :]


  # In[14]:


  # showGraph(train)
  # showGraph(test)


  # In[16]:


  look_back = 1
  trainX, trainY = create_dataset(train, look_back)
  testX, testY = create_dataset(test, look_back)


  # In[23]:


  # This algorithm don't use LSTM network
  model = Sequential()
  model.add(Dense(1, input_dim=1))
  model.add(Dense(4, activation='sigmoid'))
  model.add(Dense(1))
  model.compile(loss='mean_squared_error', optimizer='adam')


  # In[24]:


  model.fit(trainX, trainY, epochs=100, batch_size=1)


  # In[29]:


  # make predictions
  trainPredict = model.predict(trainX)
  testPredict = model.predict(testX)
  # invert predictions
  trainPredict = scaler.inverse_transform(trainPredict)
  trainY = scaler.inverse_transform([trainY])
  testPredict = scaler.inverse_transform(testPredict)
  testY = scaler.inverse_transform([testY])
  # calculate root mean squared error
  trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))
  print('Train Score: %.2f RMSE' % (trainScore))
  testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))
  print('Test Score: %.2f RMSE' % (testScore))


  # In[30]:


  # shift train predictions for plotting
  trainPredictPlot = numpy.empty_like(dataset)
  trainPredictPlot[:, :] = numpy.nan
  trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict
  # shift test predictions for plotting
  testPredictPlot = numpy.empty_like(dataset)
  testPredictPlot[:, :] = numpy.nan
  testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict
  # plot baseline and predictions
  plt.plot(scaler.inverse_transform(dataset))
  plt.plot(trainPredictPlot)
  plt.plot(testPredictPlot)
  plt.show()


  # In[55]:


  nexts = model.predict(trainX[-1])
  tomorrow_close_price = nexts[0][0] * max(data_standard.values)
  with open('result', 'a') as out:
    out.write('Train Score: %.2f RMSE' % (trainScore) + ', ' + tomorrow_close_price + '\n')
  # print(tomorrow_close_price[0])


# In[ ]:




